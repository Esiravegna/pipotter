{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Consider these symbols:\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/c8/63/bc/c863bc6b913dbc49e094ee20eddec0ed.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "When drawing with the PiNoir and using a reflective wand, they pretty much look like this:\n",
    "\n",
    "<img src=\"../../media/capture.png\" style=\"width: 200px;\">\n",
    "\n",
    "Not unlike a MNIST. Now, considering the fact that I had to draw the symbols myself, and even with the previous [augmenting](./corpus_augment.ipynb), let's create a really simple net so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "from keras.layers import Flatten, Dropout, Input, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_EPOCHS=50\n",
    "IMAGE_SHAPE=(32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spell_net(number_of_classess=6, input_shape = (32, 32, 3)):\n",
    "    \"\"\"\n",
    "    Returns a single convoluted net for MNIST given a number_of_classes and an input shape\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='valid', name='conv1', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu', use_bias=False)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(number_of_classess, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    print(\"spell net created\")\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 50\n",
    "LR = 0.0002  # initial learning rate\n",
    "B1 = 0.5  # momentum term\n",
    "GENERATED_MODEL_PATH = '../../wand/spell_net/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48000 images belonging to 6 classes.\n",
      "Found 12000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../../media/dataset/train',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=64)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        '../../media/dataset/test',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": \"arresto_momentum\", \"1\": \"locomotor\", \"2\": \"lumos\", \"3\": \"meteojinx\", \"4\": \"noctis\", \"5\": \"silencio\"}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = { v:k for k,v in train_generator.class_indices.items()} \n",
    "json.dumps(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(GENERATED_MODEL_PATH):\n",
    "    os.makedirs(GENERATED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spell net created\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 15, 15, 32)        896       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                50176     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 51,526\n",
      "Trainable params: 51,398\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "649/750 [========================>.....] - ETA: 16s - loss: 0.5300 - acc: 0.9145"
     ]
    }
   ],
   "source": [
    "train_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min'),\n",
    "    ModelCheckpoint(filepath=os.path.join(GENERATED_MODEL_PATH, \"spell_net_{epoch:02d}.h5\"),\n",
    "                    verbose=1),\n",
    "    TensorBoard(log_dir=GENERATED_MODEL_PATH, write_graph=False),   \n",
    "]\n",
    "s = spell_net(number_of_classess=test_generator.num_classes)\n",
    "s.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "s.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=(len(train_generator.filenames)) // train_generator.batch_size,\n",
    "            epochs=NUM_EPOCH,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=(len(test_generator.filenames)) // test_generator.batch_size,\n",
    "            callbacks=train_callbacks,\n",
    "            verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our network is trained. \n",
    "The latest model can be found [here](https://s3.amazonaws.com/pipotter/spell_net/spell_net.tar.gz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
