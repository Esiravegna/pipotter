{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Consider these symbols:\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/c8/63/bc/c863bc6b913dbc49e094ee20eddec0ed.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "When drawing with the PiNoir and using a reflective wand, they pretty much look like this:\n",
    "\n",
    "<img src=\"../../media/capture.png\" style=\"width: 200px;\">\n",
    "\n",
    "Not unlike a MNIST. Now, considering the fact that I had to draw the symbols myself, and even with the previous [augmenting](./corpus_augment.ipynb), let's create a really simple net so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "from keras.layers import Dense, Activation, Reshape, Input\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_EPOCHS=50\n",
    "IMAGE_SHAPE=(32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spell_net(number_of_classess=6, input_shape = (32, 32, 3)):\n",
    "    \"\"\"\n",
    "    Returns a single convoluted net for MNIST given a number_of_classes and an input shape\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='valid', name='conv1', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(number_of_classess, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    print(\"spell net created\")\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 50\n",
    "LR = 0.0002  # initial learning rate\n",
    "B1 = 0.5  # momentum term\n",
    "GENERATED_MODEL_PATH = '../../wand/spell_net/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48000 images belonging to 6 classes.\n",
      "Found 12000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./127.5,\n",
    "        shear_range=0.052,\n",
    "        zoom_range=0.05)\n",
    "test_datagen = ImageDataGenerator(rescale=1./127.5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../../media/dataset/train',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=64)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        '../../media/dataset/test',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": \"arresto_momentum\", \"1\": \"locomotor\", \"2\": \"lumos\", \"3\": \"meteojinx\", \"4\": \"noctis\", \"5\": \"silencio\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = { v:k for k,v in train_generator.class_indices.items()} \n",
    "json.dumps(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(GENERATED_MODEL_PATH):\n",
    "    os.makedirs(GENERATED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spell net created\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 15, 15, 32)        896       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               200704    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 203,014\n",
      "Trainable params: 202,694\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9811Epoch 00001: saving model to ../../wand/spell_net/models/spell_net_01.h5\n",
      "750/750 [==============================] - 347s 462ms/step - loss: 0.1336 - acc: 0.9811 - val_loss: 0.0182 - val_acc: 0.9955\n",
      "Epoch 2/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9954Epoch 00002: saving model to ../../wand/spell_net/models/spell_net_02.h5\n",
      "750/750 [==============================] - 159s 213ms/step - loss: 0.0170 - acc: 0.9954 - val_loss: 0.0358 - val_acc: 0.9887\n",
      "Epoch 3/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9964Epoch 00003: saving model to ../../wand/spell_net/models/spell_net_03.h5\n",
      "750/750 [==============================] - 204s 272ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0115 - val_acc: 0.9958\n",
      "Epoch 4/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9971Epoch 00004: saving model to ../../wand/spell_net/models/spell_net_04.h5\n",
      "750/750 [==============================] - 197s 263ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0111 - val_acc: 0.9960\n",
      "Epoch 5/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9975Epoch 00005: saving model to ../../wand/spell_net/models/spell_net_05.h5\n",
      "750/750 [==============================] - 181s 241ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "Epoch 6/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9974Epoch 00006: saving model to ../../wand/spell_net/models/spell_net_06.h5\n",
      "750/750 [==============================] - 199s 265ms/step - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0110 - val_acc: 0.9965\n",
      "Epoch 7/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9979Epoch 00007: saving model to ../../wand/spell_net/models/spell_net_07.h5\n",
      "750/750 [==============================] - 188s 250ms/step - loss: 0.0055 - acc: 0.9979 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "Epoch 8/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9978Epoch 00008: saving model to ../../wand/spell_net/models/spell_net_08.h5\n",
      "750/750 [==============================] - 192s 257ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0177 - val_acc: 0.9948\n",
      "Epoch 9/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9982Epoch 00009: saving model to ../../wand/spell_net/models/spell_net_09.h5\n",
      "750/750 [==============================] - 212s 283ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0106 - val_acc: 0.9973\n",
      "Epoch 10/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9982Epoch 00010: saving model to ../../wand/spell_net/models/spell_net_10.h5\n",
      "750/750 [==============================] - 205s 273ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0134 - val_acc: 0.9957\n",
      "Epoch 11/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9989Epoch 00011: saving model to ../../wand/spell_net/models/spell_net_11.h5\n",
      "750/750 [==============================] - 221s 295ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0081 - val_acc: 0.9978\n",
      "Epoch 12/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9984Epoch 00012: saving model to ../../wand/spell_net/models/spell_net_12.h5\n",
      "750/750 [==============================] - 291s 388ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0098 - val_acc: 0.9974\n",
      "Epoch 13/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986Epoch 00013: saving model to ../../wand/spell_net/models/spell_net_13.h5\n",
      "750/750 [==============================] - 206s 275ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0087 - val_acc: 0.9972\n",
      "Epoch 14/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9983Epoch 00014: saving model to ../../wand/spell_net/models/spell_net_14.h5\n",
      "750/750 [==============================] - 184s 246ms/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0103 - val_acc: 0.9972\n",
      "Epoch 15/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9989Epoch 00015: saving model to ../../wand/spell_net/models/spell_net_15.h5\n",
      "750/750 [==============================] - 230s 307ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0076 - val_acc: 0.9980\n",
      "Epoch 16/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9988Epoch 00016: saving model to ../../wand/spell_net/models/spell_net_16.h5\n",
      "750/750 [==============================] - 221s 295ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0070 - val_acc: 0.9975\n",
      "Epoch 17/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9987Epoch 00017: saving model to ../../wand/spell_net/models/spell_net_17.h5\n",
      "750/750 [==============================] - 183s 244ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0107 - val_acc: 0.9967\n",
      "Epoch 18/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987Epoch 00018: saving model to ../../wand/spell_net/models/spell_net_18.h5\n",
      "750/750 [==============================] - 175s 233ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0077 - val_acc: 0.9978\n",
      "Epoch 19/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990Epoch 00019: saving model to ../../wand/spell_net/models/spell_net_19.h5\n",
      "750/750 [==============================] - 165s 220ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0076 - val_acc: 0.9975\n",
      "Epoch 20/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9989Epoch 00020: saving model to ../../wand/spell_net/models/spell_net_20.h5\n",
      "750/750 [==============================] - 174s 233ms/step - loss: 0.0028 - acc: 0.9989 - val_loss: 0.0114 - val_acc: 0.9965\n",
      "Epoch 21/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991Epoch 00021: saving model to ../../wand/spell_net/models/spell_net_21.h5\n",
      "750/750 [==============================] - 171s 228ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 22/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9989Epoch 00022: saving model to ../../wand/spell_net/models/spell_net_22.h5\n",
      "750/750 [==============================] - 177s 236ms/step - loss: 0.0029 - acc: 0.9989 - val_loss: 0.0125 - val_acc: 0.9967\n",
      "Epoch 23/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9988Epoch 00023: saving model to ../../wand/spell_net/models/spell_net_23.h5\n",
      "750/750 [==============================] - 166s 221ms/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 24/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 00024: saving model to ../../wand/spell_net/models/spell_net_24.h5\n",
      "750/750 [==============================] - 169s 225ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0149 - val_acc: 0.9959\n",
      "Epoch 25/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992Epoch 00025: saving model to ../../wand/spell_net/models/spell_net_25.h5\n",
      "750/750 [==============================] - 175s 233ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0106 - val_acc: 0.9977\n",
      "Epoch 26/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9990Epoch 00026: saving model to ../../wand/spell_net/models/spell_net_26.h5\n",
      "750/750 [==============================] - 170s 226ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0062 - val_acc: 0.9983\n",
      "Epoch 27/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994Epoch 00027: saving model to ../../wand/spell_net/models/spell_net_27.h5\n",
      "750/750 [==============================] - 177s 235ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 28/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 00028: saving model to ../../wand/spell_net/models/spell_net_28.h5\n",
      "750/750 [==============================] - 116s 155ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9974\n",
      "Epoch 29/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9989Epoch 00029: saving model to ../../wand/spell_net/models/spell_net_29.h5\n",
      "750/750 [==============================] - 83s 110ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 0.0069 - val_acc: 0.9984\n",
      "Epoch 30/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993Epoch 00030: saving model to ../../wand/spell_net/models/spell_net_30.h5\n",
      "750/750 [==============================] - 77s 102ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0068 - val_acc: 0.9984\n",
      "Epoch 31/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9992Epoch 00031: saving model to ../../wand/spell_net/models/spell_net_31.h5\n",
      "750/750 [==============================] - 71s 95ms/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9976\n",
      "Epoch 32/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9991Epoch 00032: saving model to ../../wand/spell_net/models/spell_net_32.h5\n",
      "750/750 [==============================] - 72s 96ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9976\n",
      "Epoch 33/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993Epoch 00033: saving model to ../../wand/spell_net/models/spell_net_33.h5\n",
      "750/750 [==============================] - 71s 95ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9982\n",
      "Epoch 34/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9990Epoch 00034: saving model to ../../wand/spell_net/models/spell_net_34.h5\n",
      "750/750 [==============================] - 72s 95ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 0.0082 - val_acc: 0.9977\n",
      "Epoch 35/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994Epoch 00035: saving model to ../../wand/spell_net/models/spell_net_35.h5\n",
      "750/750 [==============================] - 85s 113ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0066 - val_acc: 0.9981\n",
      "Epoch 36/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9993Epoch 00036: saving model to ../../wand/spell_net/models/spell_net_36.h5\n",
      "750/750 [==============================] - 84s 112ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 0.0119 - val_acc: 0.9977\n",
      "Epoch 37/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993Epoch 00037: saving model to ../../wand/spell_net/models/spell_net_37.h5\n",
      "750/750 [==============================] - 80s 106ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0100 - val_acc: 0.9980\n",
      "Epoch 38/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994Epoch 00038: saving model to ../../wand/spell_net/models/spell_net_38.h5\n",
      "750/750 [==============================] - 73s 98ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0080 - val_acc: 0.9983\n",
      "Epoch 39/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992Epoch 00039: saving model to ../../wand/spell_net/models/spell_net_39.h5\n",
      "750/750 [==============================] - 75s 100ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0157 - val_acc: 0.9962\n",
      "Epoch 40/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992Epoch 00040: saving model to ../../wand/spell_net/models/spell_net_40.h5\n",
      "750/750 [==============================] - 73s 97ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0208 - val_acc: 0.9952\n",
      "Epoch 41/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993Epoch 00041: saving model to ../../wand/spell_net/models/spell_net_41.h5\n",
      "750/750 [==============================] - 73s 98ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0115 - val_acc: 0.9970\n",
      "Epoch 42/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9993Epoch 00042: saving model to ../../wand/spell_net/models/spell_net_42.h5\n",
      "750/750 [==============================] - 74s 99ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 43/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9992Epoch 00043: saving model to ../../wand/spell_net/models/spell_net_43.h5\n",
      "750/750 [==============================] - 74s 98ms/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0465 - val_acc: 0.9889\n",
      "Epoch 44/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995Epoch 00044: saving model to ../../wand/spell_net/models/spell_net_44.h5\n",
      "750/750 [==============================] - 74s 98ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.0113 - val_acc: 0.9978\n",
      "Epoch 45/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993Epoch 00045: saving model to ../../wand/spell_net/models/spell_net_45.h5\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0103 - val_acc: 0.9974\n",
      "Epoch 46/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995Epoch 00046: saving model to ../../wand/spell_net/models/spell_net_46.h5\n",
      "750/750 [==============================] - 86s 115ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0074 - val_acc: 0.9984\n",
      "Epoch 47/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9994Epoch 00047: saving model to ../../wand/spell_net/models/spell_net_47.h5\n",
      "750/750 [==============================] - 86s 114ms/step - loss: 0.0011 - acc: 0.9994 - val_loss: 0.0113 - val_acc: 0.9969\n",
      "Epoch 48/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992Epoch 00048: saving model to ../../wand/spell_net/models/spell_net_48.h5\n",
      "750/750 [==============================] - 87s 115ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0101 - val_acc: 0.9976\n",
      "Epoch 49/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993Epoch 00049: saving model to ../../wand/spell_net/models/spell_net_49.h5\n",
      "750/750 [==============================] - 86s 115ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0148 - val_acc: 0.9973\n",
      "Epoch 50/50\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9994Epoch 00050: saving model to ../../wand/spell_net/models/spell_net_50.h5\n",
      "750/750 [==============================] - 86s 115ms/step - loss: 0.0014 - acc: 0.9994 - val_loss: 0.0079 - val_acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9083abb38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min'),\n",
    "    ModelCheckpoint(filepath=os.path.join(GENERATED_MODEL_PATH, \"spell_net_{epoch:02d}.h5\"),\n",
    "                    verbose=1),\n",
    "    TensorBoard(log_dir=GENERATED_MODEL_PATH, write_graph=False),   \n",
    "]\n",
    "s = spell_net(number_of_classess=test_generator.num_classes)\n",
    "s.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "s.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=(len(train_generator.filenames)) // train_generator.batch_size,\n",
    "            epochs=NUM_EPOCH,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=(len(test_generator.filenames)) // test_generator.batch_size,\n",
    "            callbacks=train_callbacks,\n",
    "            verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our network is trained. \n",
    "The latest model can be found [here](https://s3.amazonaws.com/pipotter/spell_net/spell_net.tar.gz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
